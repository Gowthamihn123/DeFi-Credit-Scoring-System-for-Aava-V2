{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeFi Credit Scoring - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides exploratory analysis of Aave V2 transaction data and demonstrates the credit scoring system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data_processor import DataProcessor\n",
    "from feature_engineer import FeatureEngineer\n",
    "from model_trainer import ModelTrainer\n",
    "from scorer import WalletScorer\n",
    "from analyzer import ScoreAnalyzer\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample transaction data\n",
    "with open('../data/sample_transactions.json', 'r') as f:\n",
    "    transactions_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(transactions_data)} sample transactions\")\n",
    "print(\"\\nSample transaction:\")\n",
    "print(json.dumps(transactions_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process transactions\n",
    "processor = DataProcessor()\n",
    "processed_df = processor.process_transactions(transactions_data)\n",
    "\n",
    "print(f\"Processed data shape: {processed_df.shape}\")\n",
    "print(\"\\nProcessed data columns:\")\n",
    "print(processed_df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer features\n",
    "engineer = FeatureEngineer()\n",
    "features_df = engineer.engineer_features(processed_df)\n",
    "\n",
    "print(f\"Features shape: {features_df.shape}\")\n",
    "print(f\"Number of features: {len(features_df.columns) - 1}\")\n",
    "print(\"\\nSample features:\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "key_features = ['total_transactions', 'repayment_ratio', 'leverage_ratio', \n",
    "                'liquidation_count', 'unique_assets', 'account_age_days']\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in features_df.columns:\n",
    "        features_df[feature].hist(bins=20, ax=axes[i], alpha=0.7)\n",
    "        axes[i].set_title(f'{feature.replace(\"_\", \" \").title()}')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = ModelTrainer()\n",
    "model_package = trainer.train_model(features_df)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Model type: {type(model_package['model']).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score wallets\n",
    "scorer = WalletScorer(model_package)\n",
    "scores = scorer.score_wallets(features_df)\n",
    "\n",
    "print(f\"Scored {len(scores)} wallets\")\n",
    "print(\"\\nScore distribution:\")\n",
    "print(scores['credit_score'].describe())\n",
    "print(\"\\nRisk category distribution:\")\n",
    "print(scores['risk_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Score Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Score histogram\n",
    "scores['credit_score'].hist(bins=20, ax=axes[0], alpha=0.7, color='skyblue')\n",
    "axes[0].set_title('Credit Score Distribution')\n",
    "axes[0].set_xlabel('Credit Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(scores['credit_score'].mean(), color='red', linestyle='--', label=f'Mean: {scores[\"credit_score\"].mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Risk category pie chart\n",
    "risk_counts = scores['risk_category'].value_counts()\n",
    "axes[1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Risk Category Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive analysis\n",
    "analyzer = ScoreAnalyzer()\n",
    "analysis = analyzer.generate_comprehensive_analysis(scores, features_df)\n",
    "\n",
    "print(\"Analysis Summary:\")\n",
    "print(f\"Total wallets: {analysis['score_distribution']['total_wallets']}\")\n",
    "print(f\"Mean score: {analysis['score_distribution']['mean_score']:.2f}\")\n",
    "print(f\"Score range: {analysis['score_distribution']['min_score']:.0f} - {analysis['score_distribution']['max_score']:.0f}\")\n",
    "\n",
    "print(\"\\nBucket Distribution:\")\n",
    "for bucket, data in analysis['score_distribution']['bucket_distribution'].items():\n",
    "    print(f\"  {bucket}: {data['count']} wallets ({data['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score bucket visualization\n",
    "bucket_data = analysis['score_distribution']['bucket_distribution']\n",
    "buckets = list(bucket_data.keys())\n",
    "counts = [bucket_data[bucket]['count'] for bucket in buckets]\n",
    "percentages = [bucket_data[bucket]['percentage'] for bucket in buckets]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Count bar chart\n",
    "axes[0].bar(buckets, counts, alpha=0.7, color='lightcoral')\n",
    "axes[0].set_title('Wallet Count by Score Bucket')\n",
    "axes[0].set_xlabel('Score Bucket')\n",
    "axes[0].set_ylabel('Number of Wallets')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Percentage bar chart\n",
    "axes[1].bar(buckets, percentages, alpha=0.7, color='lightgreen')\n",
    "axes[1].set_title('Percentage Distribution by Score Bucket')\n",
    "axes[1].set_xlabel('Score Bucket')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Behavioral Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge scores with features for analysis\n",
    "merged_df = pd.merge(scores, features_df, on='wallet_address')\n",
    "\n",
    "# Correlation matrix of key features with credit score\n",
    "key_features = ['credit_score', 'total_transactions', 'repayment_ratio', 'leverage_ratio', \n",
    "                'liquidation_count', 'unique_assets', 'account_age_days']\n",
    "\n",
    "correlation_features = [f for f in key_features if f in merged_df.columns]\n",
    "correlation_matrix = merged_df[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if available)\n",
    "if hasattr(model_package['model'], 'feature_importances_'):\n",
    "    # Get feature names (limited by feature selector)\n",
    "    n_features = len(model_package['model'].feature_importances_)\n",
    "    feature_names = [f'Feature_{i}' for i in range(n_features)]\n",
    "    \n",
    "    # Create feature importance plot\n",
    "    importances = model_package['model'].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title('Feature Importance')\n",
    "    plt.bar(range(len(importances)), importances[indices], alpha=0.7)\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown report\n",
    "report = analyzer.generate_markdown_report(analysis)\n",
    "\n",
    "# Save report\n",
    "with open('../analysis.md', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Analysis report saved to ../analysis.md\")\n",
    "print(\"\\nReport preview:\")\n",
    "print(report[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This exploratory analysis demonstrates the DeFi credit scoring system's ability to:\n",
    "\n",
    "1. **Process transaction data** from Aave V2 protocol\n",
    "2. **Engineer meaningful features** that capture user behavior patterns\n",
    "3. **Train ML models** to assign credit scores\n",
    "4. **Generate comprehensive analysis** of scoring results\n",
    "\n",
    "The system successfully identifies different risk profiles and behavioral patterns among DeFi users, providing a robust foundation for credit assessment in decentralized finance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}